---
layout: default
title: Facial Emotion Detection with YOLOv11 | Real-Time on Raspberry Pi
description: Complete open-source system for detecting and classifying emotions in real-time using YOLOv11 on Raspberry Pi and edge devices. Free, well-documented, and production-ready.
keywords: emotion detection, YOLO, Raspberry Pi, computer vision, real-time detection, deep learning
---

# Facial Emotion Detection System with YOLOv11

**Real-Time Emotion Recognition on Raspberry Pi | 3-Project Ecosystem | Open Source**

[![GitHub Stars](https://img.shields.io/github/stars/MalarGIT2023/face-emotion-detection-yolo?style=social)](https://github.com/MalarGIT2023/face-emotion-detection-yolo)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![YOLOv11](https://img.shields.io/badge/YOLO-v11-brightgreen.svg)](https://docs.ultralytics.com/)
[![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-Compatible-red.svg)](https://www.raspberrypi.com/)

---

## What is This?

A **complete, production-ready system** for detecting facial emotions in real-time using state-of-the-art YOLOv11 deep learning model, optimized to run on **Raspberry Pi** and other edge devices.

Perfect for:
- ğŸ“ **Learning** AI, machine learning, and computer vision
- ğŸ”¬ **Research** on emotion recognition and edge computing
- ğŸ—ï¸ **Building** emotion-aware applications
- ğŸ­ **Deploying** at scale on multiple devices

---

## ğŸš€ Quick Start (5 Minutes)

### Get It Running Instantly

```bash
# Clone the project
git clone https://github.com/MalarGIT2023/face-emotion-detection-yolo.git
cd face-emotion-detection-yolo

# Set up environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run the demo
python app-pt.py
```

**Done!** You'll see real-time emotion detection in 5 minutes.

---

## ğŸ“Š What Does It Detect?

Classifies **10 emotions** in real-time:

| Emotion | Examples |
|---------|----------|
| ğŸ˜Š **Happy** | Smiling, laughing |
| ğŸ˜¢ **Sad** | Frowning, tears |
| ğŸ˜  **Angry** | Furrowed brow, tight jaw |
| ğŸ˜² **Excited** | Wide eyes, open mouth |
| ğŸ˜¨ **Fear** | Eyes wide, raised brows |
| ğŸ¤¢ **Disgust** | Nose wrinkle, lip curl |
| ğŸ˜ **Serious** | Neutral expression, focused |
| ğŸ¤” **Thinking** | Pondering, concentrating |
| ğŸ˜Ÿ **Worried** | Concerned, anxious |
| ğŸ˜¶ **Neutral** | No clear emotion |

---

## âš¡ Performance Metrics

Tested on **Raspberry Pi 5**:

| Metric | Value |
|--------|-------|
| **Frame Rate** | 3-5 FPS |
| **Latency** | 200-300 ms |
| **Accuracy** | ~85-90% |
| **Model Size** | 6.5 MB |
| **Memory Usage** | ~500 MB |
| **CPU Usage** | 60-80% |

*Works on Pi 4 with 2GB+ RAM too!*

---

## ğŸ—ï¸ System Architecture

This is a **3-project ecosystem** working together:

```
Step 1: Dataset Manager          Step 2: Model Training          Step 3: Real-Time Deployment
    â†“                                   â†“                                â†“
[Download Datasets]  â†’  [Train Model]  â†’  [Deploy on Pi]
   Roboflow API           YOLOv11              Live Detection
```

### The Three Projects:

#### 1. ğŸ“Š **Roboflow Dataset Manager**
- Downloads emotion datasets from Roboflow Universe
- Prepares data in YOLOv11 format
- [GitHub Repository](https://github.com/MalarGIT2023/roboflow-dataset-manager)

#### 2. ğŸ¤– **YOLOv11 Model Training**
- Trains models using transfer learning
- Fine-tunes on your data
- Produces optimized weights
- [GitHub Repository](https://github.com/MalarGIT2023/yolo-model-training)

#### 3. ğŸ¯ **Face Emotion Detection (This Project)**
- Real-time inference on edge devices
- Multi-camera support
- Optimized for Raspberry Pi
- [GitHub Repository](https://github.com/MalarGIT2023/face-emotion-detection-yolo)

---

## ğŸ¯ Key Features

âœ… **Real-Time Processing** - 3-5 FPS on Raspberry Pi  
âœ… **Edge Computing** - No cloud required, full privacy  
âœ… **Easy Setup** - Working in 5 minutes  
âœ… **Multi-Camera** - Raspberry Pi Camera + USB Webcam support  
âœ… **Optimized** - YOLOv11 Nano for edge devices  
âœ… **Production-Ready** - Used in real deployments  
âœ… **Well-Documented** - Extensive guides and examples  
âœ… **Open Source** - MIT License, community-driven  

---

## ğŸ“š Documentation

### Getting Started
- **[Complete Setup Guide](./GETTING_STARTED.md)** - Step-by-step instructions
- **[README](https://github.com/MalarGIT2023/face-emotion-detection-yolo)** - Full project details

### In-Depth Guides
- **[Dataset Management Guide](https://github.com/MalarGIT2023/roboflow-dataset-manager/blob/main/README.md)** - How to find and prepare datasets
- **[Model Training Guide](https://github.com/MalarGIT2023/yolo-model-training/blob/main/README.md)** - Train on your own data
- **[Deployment Guide](https://github.com/MalarGIT2023/face-emotion-detection-yolo/blob/main/README.md)** - Deploy anywhere

## ğŸ’» System Requirements

### Minimum
- Python 3.8+
- 2GB RAM
- Any webcam

### Recommended (Raspberry Pi)
- **Raspberry Pi 5** (4GB+ RAM) or Pi 4 (2GB+ RAM)
- Raspberry Pi Camera Module (IMX708) or USB Camera
- HDMI monitor or SSH access
- 10GB storage for datasets and training

### Optional
- GPU (NVIDIA CUDA) for faster training
- Docker for containerization
- GitHub Actions for CI/CD

---

## ğŸ“ Learning Path

### For Beginners
1. Run the quick demo
2. Read the complete guide
3. Understand how emotions are detected
4. Explore the code

### For Intermediate Users
1. Follow the complete workflow (all 3 projects)
2. Train with your own dataset
3. Modify emotion categories
4. Optimize performance

### For Advanced Users
1. Implement custom architectures
2. Deploy at scale (multiple Pis)
3. Integrate with applications
4. Contribute improvements

---

## ğŸ”¬ Use Cases

### ğŸ¥ Mental Health
Monitor emotional well-being and detect distress in real-time.

### ğŸ“Š Market Research
Analyze customer reactions and emotional responses.

### ğŸ® Gaming
Create emotion-responsive interactive experiences.

### â™¿ Accessibility
Assist non-verbal communication and support.

### ğŸ“± Mobile Applications
Embed in apps for emotion-aware features.

### ğŸ¤– Robotics
Enable robots to respond to human emotions.

---

## ğŸ† Why YOLOv11?

### Compared to Other Models

| Feature | YOLOv11 | ResNet | MobileNet |
|---------|---------|--------|-----------|
| Speed | âš¡âš¡âš¡ Fast | Medium | âš¡ Very Fast |
| Accuracy | â­â­â­â­ High | â­â­â­â­â­ Very High | â­â­â­ Good |
| Model Size | 6.5 MB | 100+ MB | 15 MB |
| Edge Device | âœ… Perfect | âŒ Slow | âœ… Good |
| Real-Time | âœ… Yes | âŒ Slow | âœ… Yes |
| Training Time | Fast | Slow | Medium |

**Result**: YOLOv11 is the sweet spot for edge devices!

---

## ğŸ”— Repository Links

| Project | GitHub | Status |
|---------|--------|--------|
| **face-emotion-detection-yolo** | [View](https://github.com/MalarGIT2023/face-emotion-detection-yolo) | â­ Main Project |
| **yolo-model-training** | [View](https://github.com/MalarGIT2023/yolo-model-training) | ğŸ“¦ Training |
| **roboflow-dataset-manager** | [View](https://github.com/MalarGIT2023/roboflow-dataset-manager) | ğŸ“Š Data |

---

## ğŸ“ˆ Getting Help

### Common Questions
- **"How do I set this up?"** â†’ [Quick Start Guide](./GETTING_STARTED.md)
- **"What hardware do I need?"** â†’ [Requirements Section](#system-requirements)
- **"How do I train with my data?"** â†’ [Training Guide](https://github.com/MalarGIT2023/yolo-model-training)
- **"How do I deploy at scale?"** â†’ [Deployment Guide](https://github.com/MalarGIT2023/face-emotion-detection-yolo)

### Need Help?
- ğŸ“– Check [GitHub Issues](https://github.com/MalarGIT2023/face-emotion-detection-yolo/issues)
- ğŸ’¬ Start a [GitHub Discussion](https://github.com/MalarGIT2023/face-emotion-detection-yolo/discussions)
- â­ Star the repo if you find it useful!

---

## ğŸ¤ Contributing

We welcome contributions! See **[CONTRIBUTING.md](./CONTRIBUTING.md)** for guidelines.

Ways to contribute:
- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ“ Improve documentation
- ğŸ”§ Submit code improvements
- ğŸ“Š Share custom datasets

---

## ğŸ“œ License

MIT License - Free to use, modify, and distribute.

See [LICENSE](https://github.com/MalarGIT2023/face-emotion-detection-yolo/blob/main/LICENSE) for details.

---

## ğŸ™ Acknowledgments

**Built for**: IEEE Mission Tomorrow Career Exploration Event  
**Presented to**: 11,000+ eighth graders in Richmond  
**Volunteered by**: IEEE Region 3 Richmond

**Technologies Used**:
- [Ultralytics YOLOv11](https://docs.ultralytics.com/)
- [PyTorch](https://pytorch.org/)
- [OpenCV](https://opencv.org/)
- [Roboflow](https://roboflow.com/)
- [Raspberry Pi](https://www.raspberrypi.com/)

---

## ğŸš€ Ready to Get Started?

### Option 1: Try the Demo (5 minutes)
```bash
git clone https://github.com/MalarGIT2023/face-emotion-detection-yolo.git
python app-pt.py
```

### Option 2: Complete Workflow (2-3 hours)
Follow the [Getting Started Guide](./GETTING_STARTED.md)

### Option 3: Learn More
Read [full documentation](https://github.com/MalarGIT2023/face-emotion-detection-yolo)

---

**Last Updated**: November 2025  
**Status**: Active Development âœ…  
**Maintained by**: [Malar (MalarGIT2023)](https://github.com/MalarGIT2023)

---

## ğŸ“Š SEO Keywords

Real-time facial emotion detection, emotion recognition deep learning, YOLOv11, Raspberry Pi machine learning, computer vision, edge computing, transfer learning, object detection, emotion classification, neural networks, real-time detection, AI for Raspberry Pi, sentiment analysis, facial expression recognition.

---

<p align="center">
  <strong>If you find this useful, please â­ star the repository!</strong>
</p>
